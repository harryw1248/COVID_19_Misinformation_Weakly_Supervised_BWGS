{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BWGS_Model\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertForMaskedLM\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from networkx import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Input directory of pre-trained BERT model\n",
    "'''\n",
    "bert_model_directory = None\n",
    "bert_tokenizer_directory = None\n",
    "\n",
    "bert_model = BertForSequenceClassification.from_pretrained(f'{bert_model_directory}', output_hidden_states= True)\n",
    "tokenizer = BertTokenizer.from_pretrained(f'{bert_tokenizer_directory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Input directory of text data to be analyzed\n",
    "'''\n",
    "covidData = None\n",
    "filename = None\n",
    "\n",
    "df = pd.read_csv(os.path.join(covidData, filename))\n",
    "df = df['message'].to_frame()\n",
    "print(df.shape) \n",
    "df.head()\n",
    "df.head(50).to_csv('training_set_BWGS_50_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Input directories for results\n",
    "'''\n",
    "\n",
    "outputFolder = None\n",
    "combinedOutputFolder = None\n",
    "modelFolder = None\n",
    "resultsFolder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word = 'conspiracy'\n",
    "relevant_tweets_csv_name = \"seed_word_\" + seed_word + \"_relevant_tweets_m11.csv\"\n",
    "words_explored = BWGS_Model.run_model(df, bert_model, tokenizer, relevant_tweets_csv_name, \n",
    "    outputFolder, combinedOutputFolder, modelFolder, resultsFolder, \n",
    "    seed_word=seed_word, similarityThreshold=0.4, maxDepth=2, topk=4, num_sample_tweets=50)\n",
    "df = pd.read_csv(os.path.join(covidData, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word = 'conspiracy'\n",
    "relevant_tweets_csv_name = \"seed_word_\" + seed_word + \"_relevant_tweets_m11.csv\"\n",
    "words_explored = BWGS_Model.run_model(df, bert_model, tokenizer, \n",
    "    relevant_tweets_csv_name, outputFolder, combinedOutputFolder, modelFolder, \n",
    "    resultsFolder, seed_word=seed_word, similarityThreshold=0.4, maxDepth=2, topk=4, num_sample_tweets=50)\n",
    "df = pd.read_csv(os.path.join(covidData, filename))\n",
    "BWGS_Model.get_relevant_tweets_plus(df, words_explored, resultsFolder, outputFolder, combinedOutputFolder, modelFolder, relevant_tweets_csv_name)\n",
    "print(\"num_misinfo_tweets: \" + str(num_misinfo_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"seed_word_false_relevant_tweets.csv\"\n",
    "df = pd.read_csv(os.path.join(covidData, filename))\n",
    "print(df.shape) \n",
    "df = df.drop_duplicates(subset='message', keep='last')\n",
    "print(df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing with unions\n",
    "\n",
    "seed_word = 'conspiracy'\n",
    "relevant_tweets_csv_name = \"seed_word_\" + seed_word + \"_relevant_tweets_m11.csv\"\n",
    "\n",
    "words_explored = BWGS_Model.run_model(df, bert_model, tokenizer, relevant_tweets_csv_name, \n",
    "    outputFolder, combinedOutputFolder, modelFolder, resultsFolder, \n",
    "    seed_word=seed_word, similarityThreshold=0.55, maxDepth=2, topk=4, num_sample_tweets=50)\n",
    "\n",
    "seed_word = 'claim'\n",
    "words_explored = BWGS_Model.run_model(df, bert_model, tokenizer, \n",
    "    relevant_tweets_csv_name, outputFolder, combinedOutputFolder, modelFolder, \n",
    "    resultsFolder, seed_word=seed_word, similarityThreshold=0.55, \n",
    "    maxDepth=2, topk=4, num_sample_tweets=50)\n",
    "\n",
    "filename = 'tweets_with_labels.csv'\n",
    "labeled_df = pd.read_csv(os.path.join(covidData, filename))\n",
    "num_tweets = labeled_df.shape[0]\n",
    "print(\"num_tweets: \" + str(num_tweets))\n",
    "relevant_tweets_csv_name = \"conspiracy_m11_labeled\"\n",
    "BWGS_Model.get_labeled_tweets(labeled_df, words_explored, resultsFolder, \n",
    "    outputFolder, combinedOutputFolder, modelFolder, relevant_tweets_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#previous result reported in paper with CMU dataset\n",
    "seed_word = 'conspiracy'\n",
    "relevant_tweets_csv_name = \"conspiracy_CMU_labeled.csv\"\n",
    "\n",
    "words_explored = BWGS_Model.run_model(df, bert_model, tokenizer, \n",
    "    relevant_tweets_csv_name, outputFolder, combinedOutputFolder, \n",
    "    modelFolder, resultsFolder, seed_word=seed_word, similarityThreshold=0.55, \n",
    "    maxDepth=4, topk=4, num_sample_tweets=50)\n",
    "\n",
    "filename = 'tweets_with_labels.csv'\n",
    "labeled_df = pd.read_csv(os.path.join(covidData, filename))\n",
    "num_tweets = labeled_df.shape[0]\n",
    "print(\"num_tweets: \" + str(num_tweets))\n",
    "BWGS_Model.get_labeled_tweets(labeled_df, words_explored, resultsFolder, \n",
    "    outputFolder, combinedOutputFolder, modelFolder, relevant_tweets_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Multi-directional experiments\n",
    "\n",
    "seed_word_1 = 'conspiracy'\n",
    "seed_word_2 = 'myth'\n",
    "\n",
    "similarityThreshold=0.45\n",
    "maxDepth=6\n",
    "topk=6\n",
    "num_sample_tweets=50\n",
    "and_option = True\n",
    "relevant_tweets_csv_name = \"CMU.csv\"\n",
    "\n",
    "words_explored = BWGS_Model.run_model_multi_directional(df, bert_model, tokenizer, \n",
    "    relevant_tweets_csv_name, outputFolder, combinedOutputFolder, modelFolder, \n",
    "    resultsFolder, df_train=None, create_df_train=True, \n",
    "    seed_word_1=seed_word_1, seed_word_2=seed_word_2, \n",
    "    similarityThreshold=similarityThreshold, maxDepth=maxDepth, \n",
    "    topk=topk, num_sample_tweets=num_sample_tweets, and_option=and_option)\n",
    "\n",
    "filename = 'tweets_with_labels.csv'\n",
    "labeled_df = pd.read_csv(os.path.join(covidData, filename))\n",
    "num_tweets = labeled_df.shape[0]\n",
    "print(\"num_tweets: \" + str(num_tweets))\n",
    "BWGS_Model.get_labeled_tweets(labeled_df, words_explored, resultsFolder, \n",
    "    outputFolder, combinedOutputFolder, modelFolder, relevant_tweets_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word = 'fake'\n",
    "words_explored = BWGS_Model.run_model(df, bert_model, tokenizer, relevant_tweets_csv_name, \n",
    "    outputFolder, combinedOutputFolder, modelFolder, resultsFolder, seed_word=seed_word, \n",
    "    similarityThreshold=0.55, maxDepth=4, topk=3, num_sample_tweets=50)\n",
    "\n",
    "print(\"words_explored\")\n",
    "print(words_explored)\n",
    "\n",
    "filename = 'tweets_with_labels.csv'\n",
    "labeled_df = pd.read_csv(os.path.join(covidData, filename))\n",
    "num_tweets = labeled_df.shape[0]\n",
    "print(\"num_tweets: \" + str(num_tweets))\n",
    "relevant_tweets_csv_name = \"conspiracy_m11_labeled\"\n",
    "BWGS_Model.get_labeled_tweets(labeled_df, words_explored, resultsFolder, \n",
    "    outputFolder, combinedOutputFolder, modelFolder, relevant_tweets_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tweets_with_labels.csv'\n",
    "labeled_df = pd.read_csv(os.path.join(covidData, filename))\n",
    "num_tweets = labeled_df.shape[0]\n",
    "print(\"num_tweets: \" + str(num_tweets))\n",
    "\n",
    "BWGS_Model.cluster_into_super_labels(labeled_df, resultsFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing on co_aid\n",
    "seed_word = 'conspiracy'\n",
    "relevant_tweets_csv_name = \"seed_word_\" + seed_word + \"_relevant_tweets_m11.csv\"\n",
    "\n",
    "words_explored = BWGS_Model.run_model(df, bert_model, tokenizer, \n",
    "    relevant_tweets_csv_name, outputFolder, combinedOutputFolder, modelFolder, \n",
    "    resultsFolder, seed_word=seed_word, similarityThreshold=0.55, maxDepth=4, topk=4, num_sample_tweets=50)\n",
    "\n",
    "filename = 'co_aid.csv'\n",
    "labeled_df = pd.read_csv(os.path.join(covidData, filename))\n",
    "num_tweets = labeled_df.shape[0]\n",
    "print(\"num_tweets: \" + str(num_tweets))\n",
    "relevant_tweets_csv_name = \"conspiracy_m11_co_aid\"\n",
    "BWGS_Model.get_labeled_tweets(labeled_df, words_explored, resultsFolder, outputFolder, \n",
    "    combinedOutputFolder, modelFolder, relevant_tweets_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word_1='conspiracy'\n",
    "seed_word_2='claim'\n",
    "similarityThreshold=0.55\n",
    "maxDepth=4\n",
    "topk=4\n",
    "num_sample_tweets=50\n",
    "and_option = False\n",
    "\n",
    "relevant_tweets_csv_name = \"conspiracy_claim.csv\"\n",
    "words_explored = BWGS_Model.run_model_multi_directional(df, bert_model, tokenizer, \n",
    "    relevant_tweets_csv_name, outputFolder, combinedOutputFolder, modelFolder, \n",
    "    resultsFolder, df_train=None, create_df_train=True, seed_word_1=seed_word_1, \n",
    "    seed_word_2=seed_word_2, similarityThreshold=similarityThreshold, maxDepth=maxDepth, \n",
    "    topk=topk, num_sample_tweets=num_sample_tweets, and_option=and_option)\n",
    "print(words_explored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COVID19FN\n",
    "seed_word = 'conspiracy'\n",
    "similarityThreshold=0.4\n",
    "maxDepth=2\n",
    "topk=6\n",
    "num_sample_tweets=50\n",
    "and_option = False\n",
    "relevant_tweets_csv_name = \"conspiracy_COVID19FN.csv\"\n",
    "\n",
    "words_explored = BWGS_Model.run_model(df, bert_model, tokenizer, \n",
    "    relevant_tweets_csv_name, outputFolder, combinedOutputFolder, modelFolder, \n",
    "    resultsFolder, seed_word=seed_word, similarityThreshold=similarityThreshold, \n",
    "    maxDepth=maxDepth, topk=topk, num_sample_tweets=50)\n",
    "\n",
    "filename = 'COVID19FN.csv'\n",
    "labeled_df = pd.read_csv(os.path.join(covidData, filename))\n",
    "num_tweets = labeled_df.shape[0]\n",
    "print(\"num_tweets: \" + str(num_tweets))\n",
    "BWGS_Model.get_labeled_tweets_fn(labeled_df, words_explored, resultsFolder, \n",
    "    outputFolder, combinedOutputFolder, modelFolder, relevant_tweets_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COVID19FN Multi-directional AND_OPTION\n",
    "seed_word_1='myth'\n",
    "seed_word_2='claim'\n",
    "similarityThreshold=0.4\n",
    "maxDepth=2\n",
    "topk=4\n",
    "num_sample_tweets=50\n",
    "and_option = True\n",
    "\n",
    "relevant_tweets_csv_name = \"conspiracy_claim.csv\"\n",
    "words_explored = BWGS_Model.run_model_multi_directional(df, bert_model, tokenizer, \n",
    "    relevant_tweets_csv_name, outputFolder, combinedOutputFolder, modelFolder, \n",
    "    resultsFolder, df_train=None, create_df_train=True, seed_word_1=seed_word_1, \n",
    "    seed_word_2=seed_word_2, similarityThreshold=similarityThreshold, maxDepth=maxDepth, \n",
    "    topk=topk, num_sample_tweets=num_sample_tweets, and_option=and_option)\n",
    "print(words_explored)\n",
    "\n",
    "filename = 'COVID19FN.csv'\n",
    "labeled_df = pd.read_csv(os.path.join(covidData, filename))\n",
    "num_tweets = labeled_df.shape[0]\n",
    "print(\"num_tweets: \" + str(num_tweets))\n",
    "BWGS_Model.get_labeled_tweets_fn(labeled_df, words_explored, \n",
    "    resultsFolder, outputFolder, combinedOutputFolder, modelFolder, relevant_tweets_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COVID19FN Multi-directional AND_OPTION\n",
    "seed_word_1='myth'\n",
    "seed_word_2='false'\n",
    "similarityThreshold=0.4\n",
    "maxDepth=2\n",
    "topk=4\n",
    "num_sample_tweets=50\n",
    "and_option = True\n",
    "\n",
    "relevant_tweets_csv_name = \"conspiracy_claim.csv\"\n",
    "words_explored = BWGS_Model.run_model_multi_directional(df, bert_model, tokenizer, \n",
    "    relevant_tweets_csv_name, outputFolder, combinedOutputFolder, modelFolder, \n",
    "    resultsFolder, df_train=None, create_df_train=True, seed_word_1=seed_word_1, \n",
    "    seed_word_2=seed_word_2, similarityThreshold=similarityThreshold, maxDepth=maxDepth, \n",
    "    topk=topk, num_sample_tweets=num_sample_tweets, and_option=and_option)\n",
    "print(words_explored)\n",
    "\n",
    "filename = 'COVID19FN.csv'\n",
    "labeled_df = pd.read_csv(os.path.join(covidData, filename))\n",
    "num_tweets = labeled_df.shape[0]\n",
    "print(\"num_tweets: \" + str(num_tweets))\n",
    "BWGS_Model.get_labeled_tweets_fn(labeled_df, words_explored, resultsFolder, \n",
    "    outputFolder, combinedOutputFolder, modelFolder, relevant_tweets_csv_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
